/*! \page reaction_diffusion_imp Implementation of reaction-diffusion equation

\tableofcontents

\section reaction_diffusion_equation Fisher's reaction-diffusion equation

Fisher's equation \cite fisher1937wave describes the population dynamics,
transformation of species into "mutant" species in space and time. Its
predictive capabilities include modelling of fire propagation, virile mutant
propagation, evolution of a neutron population in a nuclear reactor,
spreading of Alzheimer's disease in human brain, and many more phenomena.

In this tutorial, we consider the equation in its original form presented
by Fisher in 1937 \cite fisher1937wave

\f[
\frac{\partial u}{\partial t} - D \nabla^2 u =
ru\left(1-\frac{u}{k}\right)
\f]

where \f$D\f$ is diffusivity, \f$r\f$ is rate factor and \f$k\f$ is carrying
capacity. This equation can be interpreted that advancing wave with a speed no
greater than \f$\sqrt{Dr}\f$ will transform abandoned species into another
"mutant" form, switching state variable \f$u\f$ from the equilibrium state of
\f$u=0\f$ to another equilibrium state of \f$u=k\f$.

To understand equation better, we can focus our attention on the spreading of
fire on a plane of dry grass which is isolated from the rest of the domain by a
closed trench of water. Fire will spread over the whole area, where all grass
over time will be consumed by fire and transformed into ash, i.e. mutant, where
virgin (unburned) grass is indicated by \f$u=0\f$, and grass consumed by fire,
i.e. ash is \f$u=k\f$. The front of the fire will move with the velocity not
greater than \f$\sqrt{Dr}\f$. In the case with the grass is mixed with a plant
having some resistance to fire, that would be controlled by parameter \f$k\f$,
i.e. carrying capacity. Also, if there is no wind or no surface inclination, the
diffusivity parameter \f$D\f$ is scalar. On the contrary, if the ground has some
inclination or wind is present, the fire will have a tendency to go up the hill
or follow the direction of the wind, that would be accounted for by tensorial
representation of diffusivity. If the grass is of uniform height, \f$D\f$ is
equal everywhere, i.e. homogenous. If, for example, the height of the grass
varies from one place to another, diffusivity and rate factor is
heterogeneous, i.e. \f$D=D(\mathbf{x})\f$ and \f$r=r(\mathbf{x})\f$.

In this example, to keep the problem as simple as possible, we implement a
homogenous case, with isotropic diffusivity. Moreover, we assume that fire is
initiated at two places, as shown in \ref Figure1 "Figure 1" below.

\anchor Figure1
\image html reaction_diffusion_bc.png "Figure 1: Two yellow spots are placed where the fire is initiated. On boundary, Dirichlet boundary condition u = 0 is applied." width=500p

\note The estimated speed of the advancing wave can be
used further to choose the duration of analysis and length of the time step.

\section reaction_diffusion_running_code Running code

The code can run in parallel, so before starting the analysis, we have to do
mesh partitioning, such that, from very beginning, each processor stores in the
memory only one part of the mesh. In order to partition mesh, execute the script
in build directory in directory \em
basic_finite_elements/reaction_diffusion_equation 
\code
NBPROC=6 && ../../tools/mofem_part \
-my_file mesh.cub -output_file mesh.h5m -my_nparts $NBPROC -dim 2 -adj_dim 1
\endcode
where variable \em NBPROC represents the number of processors. The mesh file \em
mesh.cub is the initial mesh which can be generated by a preprocessor, for
example Cubit in this case. The partitioned mesh is saved to file \em mesh.h5m.
Having that mesh at hand, we can solve the problem by running the command line
below

\code
time mpirun -np $NBPROC ./reaction_diffusion_equation 2>&1 | tee log
\endcode

with parameters to run calculations can be found in the file \em
param_file.petsc stored in the working directory

\include
users_modules/basic_finite_elements/reaction_diffusion_equation/param_file.petsc

The key parameters are
- \em -ts_final_time: time duration
- \em -ts_dt: time step size
- \em -ts_arkimex_type: ARKIMEX time integration type
- \em -ts_adapt_type: time step adaptation (if the stiff part is not updated, it
has to be set to \em node)
- \em -snes_lag_jacobian: determines how often jacobian (stiff part) is updated.
  If set to -2 jacobian is calculated only once at the beginning of the analysis

\anchor Figure2
\image html reaction_diffusion.gif "Figure 2: Solution of the problem." width=800p

\section reaction_diffusion_discretisation Discretisation

\subsection reaction_diffusion_weak_form Semi-discrete form of the equation

To solve the equation, we apply standard Galerkin method, used in finite
element approximation, i.e. multiplying both sides by a test function and
integrate by parts to reduce demand for the regularity of tested and testing
functions, we get
\f[
\int_\Omega v \frac{\partial u}{\partial t} \textrm{d}\Omega +
\int_\Omega \nabla v \cdot D \nabla u \textrm{d}\Omega
=
\int_\Omega v r u \left(1-\frac{u}{k}\right) \textrm{d}\Omega
\f]
where \f$\Omega\f$ is solution domian. To have a unique solution, we have to a
priori enforce essential boundary conditions, such that test functions \f$v\f$
and tested function \f$u\f$ disappear on the boundary \f$\partial\Omega\f$.
Also, approximation and tested functions are in
Hilbert space \f$H^1_0(\Omega)\f$, such that integral of the first derivative
and function value over the domain is bounded. That will make the solution for
our weak equation stable and equal to the solution of the strong equation, if
smooth enough initial and boundary conditions are provided. Moreover, the
solution to the problem can be approximated by a finite-dimensional and complete
set of the piecewise mesh conforming polynomials, which are dense in
\f$H^1(\Omega)\f$, thus we will have a convergence of approximate solution to
the exact solution with mesh refinement or increasing polynomial approximation
order. The approximation of test and tested functions is given as follows

\f[
v^h = \pmb\Phi \overline{\mathbf{v}}^\textrm{T}
\quad\textrm{and}\quad
u^h = \pmb\Phi \overline{\mathbf{u}}^\textrm{T}
\f]

where \f$\pmb\Phi\f$ is the vector of
hierarchical base functions, and \f$\overline{\mathbf{v}}\f$,
\f$\overline{\mathbf{u}}\f$ are vectors of coefficients at degrees of freedom.
Utilising finite element approximation functions we finally get semi-discrete
form of the Fisher's equation

\f[
\mathbf{M} \frac{\partial \overline{\mathbf{u}}}{\partial t} + \mathbf{K}
\overline{\mathbf{u}}
=
\mathbf{G}
\f]

where

\f[
\mathbf{M} :=
\int_\Omega \pmb\Phi^\textrm{T} \pmb\Phi\, \textrm{d}\Omega,\quad
\mathbf{K} :=
\int_\Omega \nabla \pmb\Phi^\textrm{T} \nabla \pmb\Phi \,
\textrm{d}\Omega\quad\textrm{and}\quad
\mathbf{G} := \int_\Omega
\pmb\Phi^\textrm{T} \left\{ r u^h \left(1-\frac{u^h}{k}\right) \right\}
\, \textrm{d}\Omega
\f]

where \f$\mathbf{M}\f$ is so called mass matrix, \f$\mathbf{K}\f$ stiffness
matrix and \f$\mathbf{G}\f$ is source vector.

\subsection reaction_diffusion_time Time discretisation

In this section, we fully rely on time stepping algorithms briefly
described in <a
href=https://www.mcs.anl.gov/petsc/petsc-current/docs/manual.pdf>PETSc
documentation</a> in section 6. Moreover, we focus attention on IMEX method,
i.e. implicit-explicit time integration. The IMEX method is particularly useful
when two time scales are separated and present in the solution, i.e. one fast
scale, associated with \em stiff part of a differential equation, and \em slow
scale usually associated with the strongly nonlinear part of the equation. In
our particular case, \em stiff part of the equation is assisted with the
diffusion process, and slow is associated with the reaction part of the
equation. Focusing attention on our example of fire propagation, in the plane of
dry grass, \em stiff part controls the speed of advancing fire, and \em slow
part is related to the length of the burning process itself, which takes a bit
longer time. Using formalism presented in PETSc documentation, we have

\f[ \mathbf{F} \left(
t,\overline{\mathbf{u}^n}, \dot{\overline{\mathbf{u}^n}}
\right)
=
\mathbf{G}
\left(
t,\overline{\mathbf{u}^n}
\right)
\f]
where
\f[
\left.
\frac{\textrm{d}\mathbf{F}}{\textrm{d}\overline{\mathbf{u}}}
\right|_{\overline{\mathbf{u}^n}}
=
\sigma \mathbf{F}_{\dot{\overline{\mathbf{u}^n}}}
\left(
t,\overline{\mathbf{u}^n}, \dot{\overline{\mathbf{u}^n}}
\right)
+
\mathbf{F}_{\overline{\mathbf{u}^n}}
\left(
t,\overline{\mathbf{u}^n}, \dot{\overline{\mathbf{u}^n}}
\right)
=
\sigma \mathbf{M} + \mathbf{K}
\f]
where
\f[
\sigma = \left. \frac{\partial \dot{u}}{\partial u} \right|_{u^n}
\f]
is paramter provided by algortim of time integration implemented in PETSc. The
key advantage of the presented algorithm is that implementation of equation
is independent on time integration algorithm, and user can freely and quickly
change time integration method without need of changing a line of the code. The
change of time integration scheme is accounted by \f$\sigma\f$.

\section reaction_diffusion_implementation Implementation

Total control on solution process including calling functions to calculate
matrices and vectors in the right order is handled by PETSc time solver
(TS). TS call MoFEM methods iterating over finite element entities to which are
provided by Discrete Manager (DM). MoFEM is responsible for
managing degrees of freedom, finite elements, and iterating over entities on
the mesh. MOAB is the mesh database where all data are stored on mesh tags at
any point of analysis.

MoFEM and MOAB databases provide low-level functions, however in this case
flexibility of \ref MoFEM::Simple interface is adequate. \ref MoFEM::Simple
interface creates approximation fields and finite elements on the whole mesh,
and it creates problem data structures accessed by DM. DM is a bridge between
PETSc and MoFEM data structures and functions, in this particular case TS.

The programmer responsibility is to initialise data structures, methods and
provide users operators called by finite elements to evaluate matrices and
vectors when called by time solver (TS). The relation between TS functions, DM
in MoFEM and finite elements are shown in \ref Figure3 "Figure 3".

\anchor Figure3
\image html reaction_diffusion_operators.png "Figure 3: Finite elements and operators. Yellow colour indicates functions related to TS. Red colour indicates functions managed by DM. Blue colour indicates finite element instances. Green colour indicates user data operators, where dark green represents standard user data operators, and light green represents user data operators implemented for this tutorial" width=800p \note Implementation of the problem is for PDE in 2D, however, with minimal effort changing the type of element, it can be extended to 3D. Moreover is independent on time integration method, exploiting how PETSc time solver is implemented. width=800p

\subsection reaction_diffusion_mesh Setup problem

MoFEM always has to start with initialisation and the main function has the
followwing format
\code
int main(int argc, char *argv[]) {
  // initialize petsc
  const char param_file[] = "param_file.petsc";
  MoFEM::Core::Initialize(&argc, &argv, param_file, help);
  try {

    // Implementation

  }
  CATCH_ERRORS;
  // finish work cleaning memory, getting statistics, etc.
  MoFEM::Core::Finalize();
  return 0;
}
\endcode
It is worth noting that almost all MoFEM, PETSc and MOAB functions should be
checked by CHKERR which is essential for safe code development and error
detection.

In this tutorial, the initialisation of the database contains following steps

-# Main code starts with creating MOAB database and MoFEM database instances and
intefaces to each of them
\code
moab::Core mb_instance;
moab::Interface &moab = mb_instance;
MoFEM::Core core(moab);
MoFEM::Interface &m_field = core;
\endcode

-# Registration of MoFEM Discrete Manager in PETSc
\code
DMType dm_name = "DMMOFEM";
CHKERR DMRegister_MoFEM(dm_name);
\endcode

-# Loading mesh, adding fields and setting-up DM manager
\code
// Simple interface
Simple *simple_interface;
CHKERR m_field.getInterface(simple_interface);
CHKERR simple_interface->getOptions();
CHKERR simple_interface->loadFile();
// add fields
CHKERR simple_interface->addDomainField("u", H1, AINSWORTH_LEGENDRE_BASE,
                                        1);
// set fields order
CHKERR simple_interface->setFieldOrder("u", order);
// setup problem
CHKERR simple_interface->setUp();
\endcode
Note that here we add only one field \em u, in \f$H^1(\Omega)\f$ space,
approximation base is constructed following AINSWORTH_LEGENDRE_BASE recipe, and
field is a scalar field, i.e. number of coefficients for base function is 1.
Simple interface presumes that field is spanned over the whole domain, and
integration in domain will be performed over the highest dimension entities on
the mesh, in this particular example all triangles. The finite element name is
accessed through
\code
std::string fe_name = simple_interface->getDomainFEName();
\endcode
On that element,finite element instances will be executed, described
below, and on each element, user pushes a set of operators to execute. On the
other hand, finite element instances will be called through DM manager by TS
solver.

-# Getting access to the database from this point can be done exclusively
through DM
\code
MoFEM::SmartPetscObj<DM> dm = simple_interface->getDM();
\endcode
Note that MoFEM::SmartPetscObj wraps PETSc object can be used as a regular PETSc
object but user is relieved from the need of calling the destructor for it.
Having access to DM one can push finite element instances which can be used by
TS to calculate matrices and vectors at subsequent time steps.

\subsection reaction_diffusion_telling_ts Telling TS which elements should be used

In \ref Figure3 "Figure 3", yellows are PETSc functions and those on red
background are part of DM interfacing TS with MoFEM. In this tutorial TS is set
to use IMEX (implicit/explicit) method, <a
href=https://www.mcs.anl.gov/petsc/petsc-current/docs/manual.pdf>see
details</a> in section 6. Methods calculating vector and matrices needed by TS
solver to proceed set by DM functions are as follows

-# \ref MoFEM::DMMoFEMTSSetRHSFunction to calculate \f$\mathbf{G}\f$
-# \ref MoFEM::DMMoFEMTSSetIFunction to calculate \f$\mathbf{F}\f$
-# \ref MoFEM::DMMoFEMTSSetIJacobian to calculate \f$\left.
\frac{\textrm{d}\mathbf{F}}{\textrm{d}\overline{\mathbf{u}}}
\right|_{\overline{\mathbf{u}^n}}\f$
-# \ref MoFEM::DMMoFEMTSSetMonitor to set monitor run at the end of each load
step

Those functions provide sequences of finite elements (or just one element for
each term in this particular case) to calculate entries of vectors and
matrices at specific time steps.

Blue boxes mark finite elements in \ref Figure3 "Figure 3" are
created by the following code

\code
// Create finite element instances to integrate the right-hand side of slow
// and stiff vector, and the tangent left-hand side for stiff part.
boost::shared_ptr<Ele> vol_ele_slow_rhs(new Ele(m_field));
boost::shared_ptr<Ele> vol_ele_stiff_rhs(new Ele(m_field));
boost::shared_ptr<Ele> vol_ele_stiff_lhs(new Ele(m_field));
\endcode

where integration rule, controlling number of integration points on each
elment are set by
\code
auto vol_rule = [](int, int, int p) -> int { return 2 * p; };
vol_ele_slow_rhs->getRuleHook = vol_rule;
vol_ele_stiff_rhs->getRuleHook = vol_rule;
vol_ele_stiff_lhs->getRuleHook = vol_rule;
\endcode
The integration rule depends on type of operator evaluated on element, in our
case, we evaluate mass matrices, thus we need to calculate integrals exactly
with polynomial order \f$2p\f$.

Note that finite element instances implementation is generic. Elements do
problem specific calculations by providing to them user data operators which
will be described in the following sections. Three elements \em
vol_ele_slow_rhs, \em vol_ele_stiff_rhs and \em vol_ele_stiff_lhs are provided
to Discrete Manager (DM) to calculate slow and stiff vectors and Jacobian
matrix. Those three elements are instances of the class
MoFEM::FaceElementForcesAndSourcesCore. Once elements are created, we can add
them to the TS manager through the DM interface

\code
// Add element to calculate lhs of stiff part
CHKERR DMMoFEMTSSetIJacobian(dm, simple_interface->getDomainFEName(),
vol_ele_stiff_lhs, null, null);
// Add element to calculate rhs of stiff part
CHKERR DMMoFEMTSSetIFunction(dm, simple_interface->getDomainFEName(),
vol_ele_stiff_rhs, null, null);
// Add element to calculate rhs of slow (nonlinear) part
CHKERR DMMoFEMTSSetRHSFunction(dm, simple_interface->getDomainFEName(),
vol_ele_slow_rhs, null, null); \endcode

\note In case of 3D problem, user has to switch to
MoFEM::VolumeElementForcesAndSourcesCore to integrate over volume entities.
Note that all users operators implemented in the example are templates, where
the template variable is the dimension of the element. That makes implementation
dimension independent.

\subsection reaction_diffusion_telling_fe Telling finite elements which operators should be used

The problem specific matrices and vectors are implemented in namespace
\ref ReactionDiffusionEquation, by users data operators \ref
ReactionDiffusionEquation::OpEle. In this tutorial, following operators are
implemented

-# ReactionDiffusionEquation::OpAssembleMass used to calculate mass matrix
\f$\mathbf{M}\f$

-# ReactionDiffusionEquation::OpAssembleSlowRhs used to calculate the \em slow
right-hand side vector \f$\mathbf{G}\f$

-# ReactionDiffusionEquation::OpAssembleStiffRhs used to calculate the \em stiff
vector \f$\mathbf{F}\f$

-# ReactionDiffusionEquation::OpAssembleStiffLhs used to calculate the \em stiff
matrix \f$\frac{\textrm{d}\mathbf{F}}{\textrm{d} \overline{\mathbf{u}^n}}\f$

-# ReactionDiffusionEquation::Monitor used to post-process results at the end of
each time step

Implementation of each operator follows a similar pattern,

-# The class is inherited from ReactionDiffusionEquation::OpEle

-# Two types of operators are implemented
ReactionDiffusionEquation::OpEle::OPROW to calculate vectors, and
ReactionDiffusionEquation::OpEle::OPROWCOL to calculate matrices.

-# Implementation of user operator overload \em doWork member function

-# In each \em doWork method, user iterates over integration points, and then
over base functions. In case of a matrix, over base functions on rows and columns.

-# Once local element vector is assembled, \em doWork function is finalised
with assembling to global vector or global matrix.

\note More detail description on how to implement user data operator can
be found in other tutorials, for example, \ref poisson_tut2.

\subsection reaction_diffusion_common_data Common data

The data between the operator and finite elements are passed through
ReactionDiffusionEquation::CommonData
\code
struct CommonData {

  MatrixDouble grad;    ///< Gradients of field "u" at integration points
  VectorDouble val;     ///< Values of field "u" at integration points
  VectorDouble dot_val; ///< Rate of values of field "u" at integration points
  MatrixDouble invJac;  ///< Inverse of element jacobian

  SmartPetscObj<Mat> M;   ///< Mass matrix
  SmartPetscObj<KSP> ksp; ///< Linear solver

};
\endcode
which is dynamically allocated and kept by shared pointer
\code
boost::shared_ptr<CommonData> data(new CommonData());
\endcode
in addition some other operators need direct access to data, it can be safely
done by so called aliased shared pointers (<a
href=https://stackoverflow.com/questions/27109379/what-is-shared-ptrs-aliasing-constructor-for>see
here</a>)
\code
auto val_ptr = boost::shared_ptr<VectorDouble>(data, &data->val);
auto dot_val_ptr = boost::shared_ptr<VectorDouble>(data, &data->dot_val);
auto grad_ptr = boost::shared_ptr<MatrixDouble>(data, &data->grad);
\endcode

\subsection reaction_diffusion_pushing_fe Pushing operators to finite element

Each of those user data operators are added to finite element, for example to
\em vol_ele_stiff_rhs we add operators as following
\code
vol_ele_stiff_rhs->getOpPtrVector().push_back(new
MoFEM::OpCalculateInvJacForFace(data->invJac));
vol_ele_stiff_rhs->getOpPtrVector().push_back(new
MoFEM::OpSetInvJacH1ForFace(data->invJac));
vol_ele_stiff_rhs->getOpPtrVector().push_back(new
MoFEM::OpCalculateScalarValuesDot("u", dot_val_ptr));
vol_ele_stiff_rhs->getOpPtrVector().push_back(new
MoFEM::OpCalculateScalarFieldGradient<2>("u", grad_ptr));
vol_ele_stiff_rhs->getOpPtrVector().push_back(new
ReactionDiffusionEquation::OpAssembleStiffRhs<2>(data)); 
\endcode 
where MoFEM::OpCalculateInvJacForFace and MoFEM::OpSetInvJacH1ForFace are
standard operators to calculate element inverse of jacobian, and pull
derivatives of base functions to element reference configuration \f[
\frac{\partial \pmb\Phi}{\partial \mathbf{x}} = \frac{\partial
\pmb\Phi}{\partial \pmb\xi}\mathbf{J}^{-\textrm{T}} \quad\textrm{where}\quad
\mathbf{J} = \frac{\partial \mathbf{x}}{\partial \pmb\xi},\; \mathbf{x} =
\pmb\Phi(\pmb \xi) \overline{\mathbf{x}} \f] where \f$\pmb \xi\f$ are
coordinates in local element configuration, \f$\overline{\mathbf{x}}\f$ are
nodal positions or higher order coefficients in edges and faces if necessary to
describe higher order geometry. Operators MoFEM::OpCalculateScalarFieldGradient
and MoFEM::OpCalculateScalarFieldGradient are standard operators and are used to
calculate field values, and gradients of field values at integration points,
respectively. All operators in \ref Figure3 "Figure 3" marked by dark green
color are standard operators and are implemented in basic user
modules.

\subsection reaction_diffusion_g Problem with IMAX method in TS

The implementation of IMAX method in TS solver requires the user to
provide

\f[ \mathbf{g}(t,\overline{\mathbf{u}}) =
\mathbf{M}^{-1}\mathbf{G}(t,\overline{\mathbf{u}})
\f]

whereas user data operators provide vector
\f$\mathbf{G}(t,\overline{\mathbf{u}})\f$. This issue can be resolved by
exploiting finite element functionality. Each finite element class is derived
from MoFEM::BasicMethod

\code
struct BasicMethod : public KspMethod, SnesMethod, TSMethod {

  virtual MoFEMErrorCode preProcess() {
    if(preProcessHook)
      CHKERR preProcessHook()
  }
  virtual MoFEMErrorCode operator()();
  virtual MoFEMErrorCode postProcess() {
    if(preProcessHook)
      CHKERR postProcessHook()
  }

};
\endcode

Every element is run in three stages

-# \em preProcess() is executed before the code iterates over all given entity
finite elements on the mesh

-# \em operator() is executed for each entity of finite element on the mesh

-# \em postProcess() is executed after the code iterates over all given entity
finite elements on the mesh

If user provides hook to postProcess stage, after vector
\f$\mathbf{G}(t,\overline{\mathbf{u}})\f$ is calculated, can solve on place for
\f$\mathbf{g}(t,\overline{\mathbf{u}})\f$. This is done by following lambda
function

\code
auto solve_for_g = [&]() {
  MoFEMFunctionBegin;
  if (vol_ele_slow_rhs->vecAssembleSwitch) {
    CHKERR VecGhostUpdateBegin(vol_ele_slow_rhs->ts_F, ADD_VALUES,
SCATTER_REVERSE); CHKERR VecGhostUpdateEnd(vol_ele_slow_rhs->ts_F, ADD_VALUES,
SCATTER_REVERSE); CHKERR VecAssemblyBegin(vol_ele_slow_rhs->ts_F); CHKERR
VecAssemblyEnd(vol_ele_slow_rhs->ts_F); *vol_ele_slow_rhs->vecAssembleSwitch =
false;
  }
  CHKERR KSPSolve(data->ksp, vol_ele_slow_rhs->ts_F, vol_ele_slow_rhs->ts_F);
  MoFEMFunctionReturn(0);
};
\endcode

The lambda function is set as a hook to the \em slow finite element, i.e. \em
vol_ele_slow_rhs as follows \code vol_ele_slow_rhs->postProcessHook =
solve_for_g; \endcode

Note, that is also indicated on \ref Figure3 "Figure 3". In \em solve_for_g
the KSP (linear) solver is used to solve linear equation

\f[
\mathbf{M}\mathbf{g}(t,\overline{\mathbf{u}}) =
\mathbf{G}(t,\overline{\mathbf{u}})
\f]
where mass matrix \f$\mathbf{M}\f$ is calculated as follows

\code
CHKERR MatZeroEntries(data->M);
CHKERR DMCreateMatrix_MoFEM(dm, data->M);
boost::shared_ptr<Ele> vol_mass_ele(new Ele(m_field));
vol_mass_ele->getOpPtrVector().push_back(new
ReactionDiffusionEquation::OpAssembleMass(data)); CHKERR
DMoFEMLoopFiniteElements(dm, simple_interface->getDomainFEName(), vol_mass_ele);
CHKERR MatAssemblyBegin(data->M, MAT_FINAL_ASSEMBLY);
CHKERR MatAssemblyEnd(data->M, MAT_FINAL_ASSEMBLY);
\endcode

with the use on the fly created finite element \em vol_mass_ele with pushed
one operator ReactionDiffusionEquation::OpAssembleMass. The linear KSP solver
is created and set up as follows

\code
data->ksp = createKSP(m_field.get_comm());
CHKERR KSPSetOperators(data->ksp, data->M, data->M);
CHKERR KSPSetFromOptions(data->ksp); CHKERR KSPSetUp(data->ksp);
\endcode

\section reaction_diffusion_initial Initial and boundary conditions

\subsection reaction_diffusion_init Initial conditions

To set initial conditions, we use MoFEM::MeshsetsManager to get entities on the
blockset, which are set by mesh generators, for example, Cubit, Salome or gMEsh.
We assume that entities on which we set boundary conditions are set on a subset
of entities, which are listed in \em BLOCKSET 1 in the following code

\code
if (m_field.getInterface<MoFEM::MeshsetsManager>()->checkMeshset(1, BLOCKSET)) {
  Range inner_surface;
  CHKERR m_field.getInterface<MeshsetsManager>()->getEntitiesByDimension(
      1, BLOCKSET, 2, inner_surface, true);
  if (!inner_surface.empty()) {
    Range inner_surface_verts;
    CHKERR moab.get_connectivity(inner_surface, inner_surface_verts, false);
    CHKERR m_field.getInterface<FieldBlas>()->setField(
        u0, MBVERTEX, inner_surface_verts, "u");
  }
}
\endcode

-# We check if BLOCKSET 1 exist. Since the problem is solved in parallel, each
the processor keeps only part of the mesh, BLOCKSET 1 exists only on some
processors with the right set of the entities

-# If the blockset exists, we ask MoFEM::MeshsetsManager to give entities
dimension 2, i.e. faces, i.e. triangles in the blockset

-# We get all the vertices on faces, and using MoFEM::FieldBlas interface we set
values to the nodes on vertices. The value which is set is constant \f$u_0\f$.

\subsection reaction_diffusion_bc Dirichlet boundary conditions

To keep initial assumption, given in the beginning paragraphs about fire
propagation, that around the plain of dry grass we have a closed trench filled
with water, we will apply homogenous Dirichlet boundary conditions on the
boundary of the domain. To do that we follow the code

\code
Range surface;
CHKERR moab.get_entities_by_type(0, MBTRI, surface, false);
Skinner skin(&m_field.get_moab());
Range edges;
CHKERR skin.find_skin(0, surface, false, edges);
Range edges_part;
ParallelComm *pcomm = ParallelComm::get_pcomm(&moab, MYPCOMM_INDEX);
CHKERR pcomm->filter_pstatus(edges, PSTATUS_SHARED | PSTATUS_MULTISHARED,
                             PSTATUS_NOT, -1, &edges_part);
Range edges_verts;
CHKERR moab.get_connectivity(edges_part, edges_verts, false);
CHKERR m_field.getInterface<ProblemsManager>()->removeDofsOnEntities(
    simple_interface->getProblemName(), "u",
    unite(edges_verts, edges_part));
\endcode

-# Take all triangles on the mesh

-# Using Skinner implemented in MOAB, we take skin from the mesh. Consequently
we have all edges bounding part of the mesh.

-# Since we work on the parallel partitioned mesh, not all edges are on true
domain boundary. In order to filter out true boundary we use
moab::ParallelComm::filter_pstatus which is provided with MOAB interface. Using
moab::ParallelComm::filter_pstatus, we filter out all entities that are not
shared with any other processors. Finally, we obtain entities on physical domain boundary.

-# In order to enforce homogenous essential boundary conditions in the finite
element method, the simplest way is to remove degrees of freedom (DOFs) from the
problem. That is done by MoFEM::ProblemsManager interface using
MoFEM::ProblemsManager::removeDofsOnEntities function. MoFEM::ProblemsManager is
a MoFEM interface to manage DOFs and finite elements on the problem.

\section reaction_diffusion_code The plain program.

The plain program is located in
basic_finite_elements/reaction_diffusion_equation/reaction_diffusion_equation.cpp

\include reaction_diffusion_equation.cpp

*/
